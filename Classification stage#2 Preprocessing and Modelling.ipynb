{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wojci\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wojci\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\wojci\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\wojci\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "import Preprocessing as preproc\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data_hyderabad/data_preprocessed_classification.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_Preprocessed</th>\n",
       "      <th>Cuisines</th>\n",
       "      <th>meals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>[(ambience, NN), (good, JJ), (food, NN), (quit...</td>\n",
       "      <td>Chinese, Continental, Kebab, European, South I...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>[(ambience, NN), (good, JJ), (pleasant, JJ), (...</td>\n",
       "      <td>Chinese, Continental, Kebab, European, South I...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>[(must, MD), (try, VB), (great, JJ), (food, NN...</td>\n",
       "      <td>Chinese, Continental, Kebab, European, South I...</td>\n",
       "      <td>[Penne Alfredo Pasta]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Restaurant                                             Review  \\\n",
       "0  Beyond Flavours  The ambience was good, food was quite good . h...   \n",
       "1  Beyond Flavours  Ambience is too good for a pleasant evening. S...   \n",
       "2  Beyond Flavours  A must try.. great food great ambience. Thnx f...   \n",
       "\n",
       "                                 Review_Preprocessed  \\\n",
       "0  [(ambience, NN), (good, JJ), (food, NN), (quit...   \n",
       "1  [(ambience, NN), (good, JJ), (pleasant, JJ), (...   \n",
       "2  [(must, MD), (try, VB), (great, JJ), (food, NN...   \n",
       "\n",
       "                                            Cuisines                  meals  \n",
       "0  Chinese, Continental, Kebab, European, South I...                     []  \n",
       "1  Chinese, Continental, Kebab, European, South I...                     []  \n",
       "2  Chinese, Continental, Kebab, European, South I...  [Penne Alfredo Pasta]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def split_list_into_onehot_labels(dataframe, column_name):\n",
    "    \"\"\"\n",
    "    Splits a list of comma-separated values in a specified column of a DataFrame into one-hot encoded labels.\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing the data.\n",
    "        column_name (str): The name of the column containing comma-separated values to be one-hot encoded.\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the original column split into a single column containing one-hot encoded vectors.\n",
    "\n",
    "    \"\"\"\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    dataframe[column_name] = dataframe[column_name].apply(lambda x: x.split(\", \"))\n",
    "\n",
    "    cuisine_encoded = mlb.fit_transform(dataframe[column_name])\n",
    "\n",
    "    dataframe['Cuisine_Vector'] = list(cuisine_encoded)\n",
    "    return dataframe\n",
    "\n",
    "data_joined = split_list_into_onehot_labels(loaded_data, 'Cuisines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_Preprocessed</th>\n",
       "      <th>Cuisines</th>\n",
       "      <th>meals</th>\n",
       "      <th>Cuisine_Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>[(ambience, NN), (good, JJ), (food, NN), (quit...</td>\n",
       "      <td>[Chinese, Continental, Kebab, European, South ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>[(ambience, NN), (good, JJ), (pleasant, JJ), (...</td>\n",
       "      <td>[Chinese, Continental, Kebab, European, South ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>[(must, MD), (try, VB), (great, JJ), (food, NN...</td>\n",
       "      <td>[Chinese, Continental, Kebab, European, South ...</td>\n",
       "      <td>[Penne Alfredo Pasta]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Restaurant                                             Review  \\\n",
       "0  Beyond Flavours  The ambience was good, food was quite good . h...   \n",
       "1  Beyond Flavours  Ambience is too good for a pleasant evening. S...   \n",
       "2  Beyond Flavours  A must try.. great food great ambience. Thnx f...   \n",
       "\n",
       "                                 Review_Preprocessed  \\\n",
       "0  [(ambience, NN), (good, JJ), (food, NN), (quit...   \n",
       "1  [(ambience, NN), (good, JJ), (pleasant, JJ), (...   \n",
       "2  [(must, MD), (try, VB), (great, JJ), (food, NN...   \n",
       "\n",
       "                                            Cuisines                  meals  \\\n",
       "0  [Chinese, Continental, Kebab, European, South ...                     []   \n",
       "1  [Chinese, Continental, Kebab, European, South ...                     []   \n",
       "2  [Chinese, Continental, Kebab, European, South ...  [Penne Alfredo Pasta]   \n",
       "\n",
       "                                      Cuisine_Vector  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_joined.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_joined['meals'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed_groupedby_restaurant = data_preprocessed_many_rows.groupby('Restaurant').agg({\n",
    "    'Review': lambda x: ', '.join(x),\n",
    "    'Review_Preprocessed_No_Pos': lambda x: ', '.join([', '.join(tokens) for tokens in x]),\n",
    "    'Review_Preprocessed': lambda x: ', '.join([', '.join([f\"({token}, {pos})\" for token, pos in tokens]) for tokens in x]),\n",
    "    'meals': lambda x: ', '.join([meal for sublist in x for meal in eval(sublist)])\n",
    "}).reset_index().rename(columns={\"Review_Preprocessed\": \"Review_Preprocessed_Pos\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_Preprocessed_No_Pos</th>\n",
       "      <th>Review_Preprocessed_Pos</th>\n",
       "      <th>meals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Downing Street</td>\n",
       "      <td>I've been to this place about two times and i ...</td>\n",
       "      <td>' ve , place , two , time , really , like , am...</td>\n",
       "      <td>('ve, VBP), (place, NN), (two, CD), (times, NN...</td>\n",
       "      <td>lasagna , veg Platter , lasagna roll , beer , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13 Dhaba</td>\n",
       "      <td>I didn't go and eat at the Dhaba. I had ordere...</td>\n",
       "      <td>go , eat , dhaba , ordered , taste , amazing ,...</td>\n",
       "      <td>(go, VB), (eat, VB), (dhaba, NNP), (ordered, V...</td>\n",
       "      <td>lassi , Chole bhature , Lassi , chole bhature ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3B's - Buddies, Bar &amp; Barbecue</td>\n",
       "      <td>Gobind Passionate in serving Polite in nature ...</td>\n",
       "      <td>gobind , passionate , serving , polite , natur...</td>\n",
       "      <td>(gobind, NNP), (passionate, NNP), (serving, VB...</td>\n",
       "      <td>Polite , Pan ice cream , pan ice cream , pan i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AB's - Absolute Barbecues</td>\n",
       "      <td>Excellent service by nandan and rahmat and rip...</td>\n",
       "      <td>excellent , service , nandan , rahmat , ripan ...</td>\n",
       "      <td>(excellent, JJ), (service, NN), (nandan, NN), ...</td>\n",
       "      <td>ripan , politley sarvice , fish , pankaj , cak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolute Sizzlers</td>\n",
       "      <td>Service was pathetic. Ordered a sizzler with l...</td>\n",
       "      <td>service , pathetic , order , sizzler , lamb , ...</td>\n",
       "      <td>(service, NNP), (pathetic, JJ), (ordered, VBD)...</td>\n",
       "      <td>ler , lamb , lamb , Noodles , rice , noodle , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Urban Asia - Kitchen &amp; Bar</td>\n",
       "      <td>This place is highly recommended. It is workin...</td>\n",
       "      <td>place , highly , recommend , work , eat , indi...</td>\n",
       "      <td>(place, NN), (highly, RB), (recommended, JJ), ...</td>\n",
       "      <td>noodle , Sanghai Fried Rice , fish , sauce , n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Yum Yum Tree - The Arabian Food Court</td>\n",
       "      <td>It is at th floor of Act Boutique building tha...</td>\n",
       "      <td>th , floor , act , boutique , building , entra...</td>\n",
       "      <td>(th, JJ), (floor, NN), (act, NNP), (boutique, ...</td>\n",
       "      <td>mutton Haleem , Chicken Fahm Mandi , chicken h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Zega - Sheraton Hyderabad Hotel</td>\n",
       "      <td>My husband and I, visited Zega for their dimsu...</td>\n",
       "      <td>husband , visit , zega , dimsum , festival , d...</td>\n",
       "      <td>(husband, NN), (visited, VBD), (zega, NNP), (d...</td>\n",
       "      <td>thukpa , spice , dimsums , chicken Gyoza , dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Zing's Northeast Kitchen</td>\n",
       "      <td>After so many of goody goody excellent reviews...</td>\n",
       "      <td>many , goody , goody , excellent , review , n ...</td>\n",
       "      <td>(many, JJ), (goody, NN), (goody, NN), (excelle...</td>\n",
       "      <td>chalega , pork , beef , meat , meat , veg momo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>eat.fit</td>\n",
       "      <td>I had ordered gobi methi paratha.. it was ok. ...</td>\n",
       "      <td>order , gobi , methi , paratha , ok . , good ,...</td>\n",
       "      <td>(ordered, VBN), (gobi, JJ), (methi, NN), (para...</td>\n",
       "      <td>gobi methi paratha , paratha , rice , thali , ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Restaurant  \\\n",
       "0                       10 Downing Street   \n",
       "1                                13 Dhaba   \n",
       "2          3B's - Buddies, Bar & Barbecue   \n",
       "3               AB's - Absolute Barbecues   \n",
       "4                       Absolute Sizzlers   \n",
       "..                                    ...   \n",
       "95             Urban Asia - Kitchen & Bar   \n",
       "96  Yum Yum Tree - The Arabian Food Court   \n",
       "97        Zega - Sheraton Hyderabad Hotel   \n",
       "98               Zing's Northeast Kitchen   \n",
       "99                                eat.fit   \n",
       "\n",
       "                                               Review  \\\n",
       "0   I've been to this place about two times and i ...   \n",
       "1   I didn't go and eat at the Dhaba. I had ordere...   \n",
       "2   Gobind Passionate in serving Polite in nature ...   \n",
       "3   Excellent service by nandan and rahmat and rip...   \n",
       "4   Service was pathetic. Ordered a sizzler with l...   \n",
       "..                                                ...   \n",
       "95  This place is highly recommended. It is workin...   \n",
       "96  It is at th floor of Act Boutique building tha...   \n",
       "97  My husband and I, visited Zega for their dimsu...   \n",
       "98  After so many of goody goody excellent reviews...   \n",
       "99  I had ordered gobi methi paratha.. it was ok. ...   \n",
       "\n",
       "                           Review_Preprocessed_No_Pos  \\\n",
       "0   ' ve , place , two , time , really , like , am...   \n",
       "1   go , eat , dhaba , ordered , taste , amazing ,...   \n",
       "2   gobind , passionate , serving , polite , natur...   \n",
       "3   excellent , service , nandan , rahmat , ripan ...   \n",
       "4   service , pathetic , order , sizzler , lamb , ...   \n",
       "..                                                ...   \n",
       "95  place , highly , recommend , work , eat , indi...   \n",
       "96  th , floor , act , boutique , building , entra...   \n",
       "97  husband , visit , zega , dimsum , festival , d...   \n",
       "98  many , goody , goody , excellent , review , n ...   \n",
       "99  order , gobi , methi , paratha , ok . , good ,...   \n",
       "\n",
       "                              Review_Preprocessed_Pos  \\\n",
       "0   ('ve, VBP), (place, NN), (two, CD), (times, NN...   \n",
       "1   (go, VB), (eat, VB), (dhaba, NNP), (ordered, V...   \n",
       "2   (gobind, NNP), (passionate, NNP), (serving, VB...   \n",
       "3   (excellent, JJ), (service, NN), (nandan, NN), ...   \n",
       "4   (service, NNP), (pathetic, JJ), (ordered, VBD)...   \n",
       "..                                                ...   \n",
       "95  (place, NN), (highly, RB), (recommended, JJ), ...   \n",
       "96  (th, JJ), (floor, NN), (act, NNP), (boutique, ...   \n",
       "97  (husband, NN), (visited, VBD), (zega, NNP), (d...   \n",
       "98  (many, JJ), (goody, NN), (goody, NN), (excelle...   \n",
       "99  (ordered, VBN), (gobi, JJ), (methi, NN), (para...   \n",
       "\n",
       "                                                meals  \n",
       "0   lasagna , veg Platter , lasagna roll , beer , ...  \n",
       "1   lassi , Chole bhature , Lassi , chole bhature ...  \n",
       "2   Polite , Pan ice cream , pan ice cream , pan i...  \n",
       "3   ripan , politley sarvice , fish , pankaj , cak...  \n",
       "4   ler , lamb , lamb , Noodles , rice , noodle , ...  \n",
       "..                                                ...  \n",
       "95  noodle , Sanghai Fried Rice , fish , sauce , n...  \n",
       "96  mutton Haleem , Chicken Fahm Mandi , chicken h...  \n",
       "97  thukpa , spice , dimsums , chicken Gyoza , dim...  \n",
       "98  chalega , pork , beef , meat , meat , veg momo...  \n",
       "99  gobi methi paratha , paratha , rice , thali , ...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "        doc = nlp(text)\n",
    "        return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "\n",
    "def transform_and_group_dataframe(df):\n",
    "    \n",
    "    df = df[df['meals'].apply(lambda x: len(x) > 0)]  # drop the rows where there were no meals mentioned\n",
    "\n",
    "    df['Review_Preprocessed_No_Pos'] = df['Review_Preprocessed'].apply(lambda x: [token for token, pos in x])  # extract token from the tuple\n",
    "\n",
    "    # Grouping\n",
    "    df = df.groupby('Restaurant').agg({\n",
    "        'Review': lambda x: ', '.join(x),\n",
    "        'Review_Preprocessed_No_Pos': lambda x: ', '.join([', '.join(tokens) for tokens in x]),\n",
    "        'Review_Preprocessed': lambda x: ', '.join([', '.join([f\"({token}, {pos})\" for token, pos in tokens]) for tokens in x]),\n",
    "        'meals': lambda x: ', '.join([meal for sublist in x for meal in sublist])\n",
    "    }).reset_index().rename(columns={\"Review_Preprocessed\": \"Review_Preprocessed_Pos\"})\n",
    "\n",
    "    columns_to_lower = ['Review_Preprocessed_No_Pos', 'meals']\n",
    "\n",
    "    df[columns_to_lower] = df[columns_to_lower].apply(lambda x: x.apply(lemmatize_text))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "test = transform_and_group_dataframe(data_joined)\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-mining1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
